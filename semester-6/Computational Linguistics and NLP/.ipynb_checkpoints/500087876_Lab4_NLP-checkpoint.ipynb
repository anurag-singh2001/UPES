{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ru6uq0-ZcWk"
   },
   "source": [
    "Name - Sarthak Patel\n",
    "Roll - R2142201919\n",
    "Sap Id - 500087876\n",
    "Batch - B5(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGCTY5zbPZhf",
    "outputId": "f595e08f-e032-4cdb-a6af-15932435840c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0fa_0TKPP4YB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMNx2tzzPc4j",
    "outputId": "5dd0973b-8903-40ab-87fc-434f3c0399d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              created_at                                         tweet_text\n",
      "0    2023-01-29 16:50:27                                   @guydealership 不\n",
      "1    2023-01-29 06:04:17                                    @mhauken useful\n",
      "2    2023-01-29 05:45:53   @chrisjbakke i could *really* use those features\n",
      "3    2023-01-29 05:30:51                                     @chrisjbakke 不\n",
      "4    2023-01-29 03:49:33                   @mysteriouskat good feature list\n",
      "..                   ...                                                ...\n",
      "145  2023-01-23 04:54:34                                    @nicolebehnam 不\n",
      "146  2023-01-23 02:27:37       @muskuniversity major respect for the makers\n",
      "147  2023-01-22 23:09:03  @wallstreetsilv @srsroccoreport no change in c...\n",
      "148  2023-01-22 23:05:51  @mtaibbi another case of parody &amp; reality ...\n",
      "149  2023-01-22 23:03:16                                      @emollick wow\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"/content/tweets.csv\")\n",
    "\n",
    "# convert strings in all columns to lowercase\n",
    "df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TQD9CHF6U-SP",
    "outputId": "528ffe56-ee1a-4f96-f12e-2ff23cffdc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              created_at                                         tweet_text\n",
      "0    2023-01-29 16:50:27                                   @guydealership 不\n",
      "1    2023-01-29 06:04:17                                    @mhauken useful\n",
      "2    2023-01-29 05:45:53   @chrisjbakke i could *really* use those features\n",
      "3    2023-01-29 05:30:51                                     @chrisjbakke 不\n",
      "4    2023-01-29 03:49:33                   @mysteriouskat good feature list\n",
      "..                   ...                                                ...\n",
      "145  2023-01-23 04:54:34                                    @nicolebehnam 不\n",
      "146  2023-01-23 02:27:37       @muskuniversity major respect for the makers\n",
      "147  2023-01-22 23:09:03  @wallstreetsilv @srsroccoreport no change in c...\n",
      "148  2023-01-22 23:05:51  @mtaibbi another case of parody &amp; reality ...\n",
      "149  2023-01-22 23:03:16                                      @emollick wow\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['tweet_text'] = df.tweet_text.str.lower()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sz-x1xFKVlbI",
    "outputId": "e26b3a3f-c9df-4d27-96e1-1fadd7a08006"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     [@guydealership 不]\n",
      "1                                      [@mhauken useful]\n",
      "2      [@chrisjbakke i could *really* use those featu...\n",
      "3                                       [@chrisjbakke 不]\n",
      "4                     [@mysteriouskat good feature list]\n",
      "                             ...                        \n",
      "145                                    [@nicolebehnam 不]\n",
      "146       [@muskuniversity major respect for the makers]\n",
      "147    [@wallstreetsilv @srsroccoreport no change in ...\n",
      "148    [@mtaibbi another case of parody &amp; reality...\n",
      "149                                      [@emollick wow]\n",
      "Name: sentences, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "df['sentences'] = df['tweet_text'].apply(lambda x: sent_tokenize(x))\n",
    "\n",
    "print(df['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWcfQKimWUix",
    "outputId": "74832f28-ddd3-454e-9414-56d8fce392ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                  [@, guydealership, 不]\n",
      "1                                   [@, mhauken, useful]\n",
      "2      [@, chrisjbakke, i, could, *, really, *, use, ...\n",
      "3                                    [@, chrisjbakke, 不]\n",
      "4                [@, mysteriouskat, good, feature, list]\n",
      "                             ...                        \n",
      "145                                 [@, nicolebehnam, 不]\n",
      "146    [@, muskuniversity, major, respect, for, the, ...\n",
      "147    [@, wallstreetsilv, @, srsroccoreport, no, cha...\n",
      "148    [@, mtaibbi, another, case, of, parody, &, amp...\n",
      "149                                   [@, emollick, wow]\n",
      "Name: words, Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['words'] = df['tweet_text'].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "print(df['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Fuqolau6XJeA"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Avn75lKyXkjn",
    "outputId": "84afc353-abc0-48a3-d12e-2d5bf05569bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              created_at                                         tweet_text  \\\n",
      "0    2023-01-29 16:50:27                                   @guydealership 不   \n",
      "1    2023-01-29 06:04:17                                    @mhauken useful   \n",
      "2    2023-01-29 05:45:53   @chrisjbakke i could *really* use those features   \n",
      "3    2023-01-29 05:30:51                                     @chrisjbakke 不   \n",
      "4    2023-01-29 03:49:33                   @mysteriouskat good feature list   \n",
      "..                   ...                                                ...   \n",
      "145  2023-01-23 04:54:34                                    @nicolebehnam 不   \n",
      "146  2023-01-23 02:27:37       @muskuniversity major respect for the makers   \n",
      "147  2023-01-22 23:09:03  @wallstreetsilv @srsroccoreport no change in c...   \n",
      "148  2023-01-22 23:05:51  @mtaibbi another case of parody &amp; reality ...   \n",
      "149  2023-01-22 23:03:16                                      @emollick wow   \n",
      "\n",
      "                                             sentences  \\\n",
      "0                                   [@guydealership 不]   \n",
      "1                                    [@mhauken useful]   \n",
      "2    [@chrisjbakke i could *really* use those featu...   \n",
      "3                                     [@chrisjbakke 不]   \n",
      "4                   [@mysteriouskat good feature list]   \n",
      "..                                                 ...   \n",
      "145                                  [@nicolebehnam 不]   \n",
      "146     [@muskuniversity major respect for the makers]   \n",
      "147  [@wallstreetsilv @srsroccoreport no change in ...   \n",
      "148  [@mtaibbi another case of parody &amp; reality...   \n",
      "149                                    [@emollick wow]   \n",
      "\n",
      "                                                 words  \\\n",
      "0                                [@, guydealership, 不]   \n",
      "1                                 [@, mhauken, useful]   \n",
      "2    [@, chrisjbakke, i, could, *, really, *, use, ...   \n",
      "3                                  [@, chrisjbakke, 不]   \n",
      "4              [@, mysteriouskat, good, feature, list]   \n",
      "..                                                 ...   \n",
      "145                               [@, nicolebehnam, 不]   \n",
      "146  [@, muskuniversity, major, respect, for, the, ...   \n",
      "147  [@, wallstreetsilv, @, srsroccoreport, no, cha...   \n",
      "148  [@, mtaibbi, another, case, of, parody, &, amp...   \n",
      "149                                 [@, emollick, wow]   \n",
      "\n",
      "                                         stemmed_words  \n",
      "0                                [@, guydealership, 不]  \n",
      "1                                    [@, mhauken, use]  \n",
      "2    [@, chrisjbakk, i, could, *, realli, *, use, t...  \n",
      "3                                   [@, chrisjbakk, 不]  \n",
      "4               [@, mysteriouskat, good, featur, list]  \n",
      "..                                                 ...  \n",
      "145                               [@, nicolebehnam, 不]  \n",
      "146  [@, muskunivers, major, respect, for, the, maker]  \n",
      "147  [@, wallstreetsilv, @, srsroccoreport, no, cha...  \n",
      "148  [@, mtaibbi, anoth, case, of, parodi, &, amp, ...  \n",
      "149                                 [@, emollick, wow]  \n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df['stemmed_words'] = df['words'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7qaNr5IYiZb",
    "outputId": "28f2db6c-cff2-4cc1-bb7e-cd4de1a6fe5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              created_at                                         tweet_text  \\\n",
      "0    2023-01-29 16:50:27                                   @guydealership 不   \n",
      "1    2023-01-29 06:04:17                                    @mhauken useful   \n",
      "2    2023-01-29 05:45:53   @chrisjbakke i could *really* use those features   \n",
      "3    2023-01-29 05:30:51                                     @chrisjbakke 不   \n",
      "4    2023-01-29 03:49:33                   @mysteriouskat good feature list   \n",
      "..                   ...                                                ...   \n",
      "145  2023-01-23 04:54:34                                    @nicolebehnam 不   \n",
      "146  2023-01-23 02:27:37       @muskuniversity major respect for the makers   \n",
      "147  2023-01-22 23:09:03  @wallstreetsilv @srsroccoreport no change in c...   \n",
      "148  2023-01-22 23:05:51  @mtaibbi another case of parody &amp; reality ...   \n",
      "149  2023-01-22 23:03:16                                      @emollick wow   \n",
      "\n",
      "                                             sentences  \\\n",
      "0                                   [@guydealership 不]   \n",
      "1                                    [@mhauken useful]   \n",
      "2    [@chrisjbakke i could *really* use those featu...   \n",
      "3                                     [@chrisjbakke 不]   \n",
      "4                   [@mysteriouskat good feature list]   \n",
      "..                                                 ...   \n",
      "145                                  [@nicolebehnam 不]   \n",
      "146     [@muskuniversity major respect for the makers]   \n",
      "147  [@wallstreetsilv @srsroccoreport no change in ...   \n",
      "148  [@mtaibbi another case of parody &amp; reality...   \n",
      "149                                    [@emollick wow]   \n",
      "\n",
      "                                                 words  \\\n",
      "0                                [@, guydealership, 不]   \n",
      "1                                 [@, mhauken, useful]   \n",
      "2    [@, chrisjbakke, i, could, *, really, *, use, ...   \n",
      "3                                  [@, chrisjbakke, 不]   \n",
      "4              [@, mysteriouskat, good, feature, list]   \n",
      "..                                                 ...   \n",
      "145                               [@, nicolebehnam, 不]   \n",
      "146  [@, muskuniversity, major, respect, for, the, ...   \n",
      "147  [@, wallstreetsilv, @, srsroccoreport, no, cha...   \n",
      "148  [@, mtaibbi, another, case, of, parody, &, amp...   \n",
      "149                                 [@, emollick, wow]   \n",
      "\n",
      "                                         stemmed_words  \\\n",
      "0                                [@, guydealership, 不]   \n",
      "1                                    [@, mhauken, use]   \n",
      "2    [@, chrisjbakk, i, could, *, realli, *, use, t...   \n",
      "3                                   [@, chrisjbakk, 不]   \n",
      "4               [@, mysteriouskat, good, featur, list]   \n",
      "..                                                 ...   \n",
      "145                               [@, nicolebehnam, 不]   \n",
      "146  [@, muskunivers, major, respect, for, the, maker]   \n",
      "147  [@, wallstreetsilv, @, srsroccoreport, no, cha...   \n",
      "148  [@, mtaibbi, anoth, case, of, parodi, &, amp, ...   \n",
      "149                                 [@, emollick, wow]   \n",
      "\n",
      "                                      lemmatized_words  \n",
      "0                                [@, guydealership, 不]  \n",
      "1                                 [@, mhauken, useful]  \n",
      "2    [@, chrisjbakke, i, could, *, really, *, use, ...  \n",
      "3                                  [@, chrisjbakke, 不]  \n",
      "4              [@, mysteriouskat, good, feature, list]  \n",
      "..                                                 ...  \n",
      "145                               [@, nicolebehnam, 不]  \n",
      "146  [@, muskuniversity, major, respect, for, the, ...  \n",
      "147  [@, wallstreetsilv, @, srsroccoreport, no, cha...  \n",
      "148  [@, mtaibbi, another, case, of, parody, &, amp...  \n",
      "149                                 [@, emollick, wow]  \n",
      "\n",
      "[150 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_words'] = df['words'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
